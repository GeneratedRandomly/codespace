# 网安导 4-10 章作业
## 第11章
1. 简述真实源地址认证 SAVA 体系结构的三个设计原则和原因。
   - **可扩展性**：SAVA体系结构是可演进的体系结构，应具备可扩展性以适应复杂的网络环境以及新的需求，支持在整个互联网不同位置、不同粒度需求的大规模部署。
   - **兼容性**：SAVA体系结构建立在当前互联网体系结构基础上，整体的技术依附于现有体系结构实现，因此必须要求技术对应协议与现有体系结构协议兼容。
   - **安全性**：SAVA体系结构的构建是支撑真实可信互联网体系结构实现，通过将安全性赋予现有体系结构，弥补其信任缺失的问题，所以保障SAVA自身的安全性至关重要。
2. 面向地址域的真实源地址认证 SAVA 体系结构的三层结构是什么？简述每层结构的作用。
   - 接入网、地址域内和地址域间三层结构。
   - 接入层面提供主机粒度的源地址验证能力，以保证地址使用的可追溯性。
   - 在地址域内层面提供前缀级别的保护能力，以保护核心设备不被攻击。
   - 在地址域间层面提供地址域级别的联盟内可验证能力以及保护自身不被伪造的能力。
## 第12章
1. 请简述统计特征驱动的流量识别方案中基于数据包粒度特征的检测方法和基于流粒度特征的检测方法的优劣。
   - 基于流粒度特征相比于包粒度特征的优势：相比包级别特征考虑了数据包之间的关联关系，因而可以检测出更加复杂的攻击；此外解决了性能开销的问题，距离大规模部署更近了一步。
   - 基于流粒度特征相比于包粒度检测的劣势：缺乏数据包级别细粒度的分析。
2. 请简述针对 Tor 的网站指纹攻击和流量关联攻击有什么相同点和不同点。
   - 相同点：都利用流量特征分析用户行为，威胁匿名性。
   - 不同点：网站指纹攻击识别访问网站类型，流量关联攻击关联入口与出口流量，追踪用户身份。
## 第13章
1. 请简述构建 TLS 交互信道的过程中，TLS 协议所提供的安全功能，并解释 TLS 协议如何提供这些功能。
   - 数据完整性：验证数据是否伪造而来或未遭篡改过。
   - 身份认证：获取通信方的身份，为访问控制机制作支撑。
   - 数据加密：协商会话密钥用于数据加密，防止第三方窃听传输数据。
   - TLS 基于 PKI 获取对方公钥证书，基于公钥非对称加密协商随机数，基于协商的随机数生成会话密钥，从而建立安全信道，基于会话密钥对传输数据加密，并生成消息认证码对消息完整性进行验证。
2. 请举例说明访问控制的三种类型，并说明访问控制所面临的局限性。
   - 基于角色的访问控制：如企业中员工根据其角色（如普通员工、经理、管理员）被授予不同的系统访问权限。
   - 基于属性的访问控制：如根据用户的部门、工作时间、设备类型等属性动态决定其对资源的访问权限，例如只有在公司网络内且使用公司设备才能访问敏感数据。
   - 基于信任管理的访问控制：如云服务中，用户通过第三方认证（如OAuth、SAML）获得访问权限，系统根据用户的信任级别分配资源访问权。
   - 局限性：访问控制只能解决被访问者对访问者的信任问题，但无法解决访问者对被访问者的信任问题，访问者可能访问到恶意、无效资源。
## 第14章
1. 请简单介绍反射型 XSS 和持久型 XSS 并阐述其差异。
   - 反射型XSS（非持久型 XSS）：攻击者发送带有恶意脚本参数的URL诱骗受害者点击
   - 存储型XSS（持久型 XSS）：攻击者使用网站漏洞，将可执行的代码永久存在服务器中，从而任意访问被攻击网站的用户都会执行恶意代码的攻击
2. 请简单描述单个 Web 应用的 1）资源有限和 2）部分服务的数据共享分别会带来什么问题，并举例说明。
   - 资源有限：易被拒绝服务攻击（如通过向服务器提交大量请求，使服务器超负荷）。
   - 数据共享：可能导致越权访问或数据泄露（如多租户环境下数据隔离不严）。
## 第15章
1. 列举 5 个人工智能框架漏洞。
   - TensorFlow CVE-2020-15190 段错误漏洞
   - TensorFlow read_file() write_file() 两种操作可以在模型运行时操纵文件的读写，导致信息泄露。
   - PyTorch 内存泄露
   - Keras 权重丢失
   - Caffe SQL注入漏洞
2. 投毒攻击和对抗攻击的联系与区别是什么？
   - 联系：都旨在误导模型输出错误结果。
   - 区别：投毒攻击在训练阶段篡改数据，对抗攻击在决策输出阶段构造特殊输入。
3. 成员推理攻击的基本原理是什么？
   - 模型对于训练集样本一定是“过拟合”的，如果一个模型对某个样本给出了非常自信的预测，那这个样本很可能是模型“见过”的。
   - 准备数据，训练 Shadow Model 模拟目标模型行为，训练攻击模型
## 第16章
1. 列举大模型常见的数据安全风险，并分别简要概括其危害。
   - 数据泄漏：敏感数据被大模型“记住”导致数据泄漏
   - 偏见与毒性：有偏见的训练数据导致大模型针对不同群体、个体或情境生成不公正或不准确的结果
   - 幻觉问题：编造事实、错误推理、动摇用户信心
   - 多模态数据欺骗：通过干扰正常多模态数据输入或者主动生成难以分辨的虚假多模态数据，可以绕过大模型的安全防御机制，干扰大模型决策过程，导致各种攻击端后果（攻破人脸识别、造成无人机坠机等）
   - 生成内容滥用：生成式人工智能具备高通用性的特点，低使用门槛大幅增加了已有风险的安全威胁，降低恶意攻击门槛、虚假信息泛滥、侵害合法权益、加大电信诈骗风险。
2. 简述针对大模型的恶意输入攻击的典型防御方法。
   - 面向大模型的有害提示语输入检测：基于黑名单过滤算法、基于有害内容检测器和基于大模型的输入检测方法
   - 面向大模型的有害提示语修改：安全提示语、调整提示语顺序、修改提示语格式